라이브러리를 import 한다.
데이터 세트를 임포트 한다.
head() 명령어를 이용해서 데이터가 잘 불러져왔는지 확인한다.
shape를 통해서 훈련 세트와 테스트 세트의 갯수가 잘 나뉘어져 있는지. 훈련 세트의 컬럼 값이 테스트 세트보다 하나 더 많은지 (타겟 값) 확인한다.
대충 여러가지 시각화를 통해서 어떻게 분포되어있는지 봐준다.
훈련 세트와 테스트 세트를 합쳐서 한번에 데이터 processing을 수행해야 한다.
리스트 형태로 concat을 활용하여 넣어준다.
타겟값으로 Nan값이 test세트의 갯수만큼 나와있는지 확인해준다.
object feature들을 factorize를 활용해서 레이블링 해준다.
Null 값을 일괄 변환해주는데, fillna를 활용해서 전부 채워준다
결측값을 -999로 채워준 후에 데이터를 다시 분리한다.
학습 데이터를 검증 데이터로 분리하고 LGBM Classifier로 학습을 수행한다.
ID값과 TARGET값을 제외한 후 만큼을 featrue app으로 할당한다
타겟값만을 target_app으로 할당한다.

훈련세트와 테스트세트가 이미 나뉘어져 있다면, 훈련세트를 validation 세트로 나누어 줘서 평가해보도록 한다.
lgbm에 넣어본다.

feature importance를 통해서 어떤 피처가 더 중요하게 작용하는지 확인해준다.

학습된 classifer를 이용하여 테스트 데이터를 예측하고 결과를 kaggle submit해준다.
같은 내용을 Titanic에 활용해보면 좋을 것 같다.
